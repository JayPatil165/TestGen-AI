# ğŸš€ TestGen AI

> **"The Autonomous QA Agent from Your CLI"**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

A Python-based CLI package that acts as an **"Autonomous QA Pair-Programmer."** It lives in your terminal and automates the tedious parts of software testing: understanding code, writing test cases, running them, and formatting reports.

With **Watch Mode**, TestGen AI writes tests while you write code, enabling true **Test-Driven Development** without the overhead.

---

## âœ¨ Features

- ğŸ¤– **AI-Powered Test Generation** - Automatically generates comprehensive test suites using LLMs (OpenAI, Claude, Ollama)
- ğŸ“Š **Beautiful Terminal Dashboard** - Rich, color-coded test execution matrix with real-time feedback
- ğŸ‘€ **Watch Mode** - Real-time TDD with automatic test generation as you code
- ğŸ“ˆ **HTML/PDF Reports** - Professional test reports for stakeholders
- âš¡ **Smart Context Extraction** - Intelligently parses code to minimize LLM costs
- ğŸ¯ **Multiple Test Frameworks** - Supports Pytest and Playwright for UI testing
- ğŸ”„ **One-Click Workflow** - `testgen auto` does everything: generate â†’ test â†’ report

---

## ğŸ¯ The "AGER" Architecture

TestGen AI operates on a localized 4-step loop:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analyze  â”‚â”€â”€â”€â”€â–¶â”‚ Generate â”‚â”€â”€â”€â”€â–¶â”‚ Execute  â”‚â”€â”€â”€â”€â–¶â”‚ Report   â”‚
â”‚ (Scanner)â”‚     â”‚ (Brain)  â”‚     â”‚ (Runner) â”‚     â”‚ (Visuals)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### A - Analyze (The Scanner)
- Reads your project directory
- Filters noise (`node_modules`, `.git`, etc.)
- Extracts function signatures and docstrings for large files
- Keeps LLM costs low with smart context management

### G - Generate (The Brain)
- Sends context to LLMs (OpenAI/Ollama/Claude)
- Receives executable Python/Pytest code
- Writes test files to the `tests/` directory
- **Watch Mode**: Listens for file saves and triggers generation instantly

### E - Execute (The Runner)
- Identifies test types (Unit vs. UI)
- Runs test frameworks (Pytest/Playwright) in subprocesses
- Captures logs and exit codes

### R - Report (The Visuals)
- Parses execution data
- Renders beautiful CLI matrices
- Compiles persistent HTML reports

---

## ğŸ“¦ Installation

### Prerequisites
- Python 3.10 or higher
- pip package manager

### Install from PyPI *(Coming Soon)*
```bash
pip install testgen-ai
```

### Install from Source
```bash
# Clone the repository
git clone https://github.com/JayPatil165/TestGen-AI.git
cd TestGen-AI

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install in editable mode
pip install -e .
```

---

## ğŸš€ Quick Start

### 1. Configure API Keys

Create a `.env` file in your project root:

```bash
OPENAI_API_KEY=sk-your-key-here
# OR
ANTHROPIC_API_KEY=your-claude-key
# OR use Ollama (local, no API key needed)
```

### 2. Run Your First Test Generation

```bash
# Generate tests for your project
testgen generate ./src

# Run the generated tests
testgen test

# Generate HTML report
testgen report

# Or do everything at once (God Mode)
testgen auto
```

### 3. Enable Watch Mode (Real-time TDD)

```bash
# Watch your code and auto-generate tests as you type
testgen generate ./src --watch
```

---

## ğŸ¨ CLI Commands

### Command Matrix

| Command | Purpose | What It Does | Special Flags |
|---------|---------|--------------|---------------|
| `testgen generate` | Create test files | Analyzes code â†’ Calls LLM â†’ Saves tests | `--watch` (Live AI) |
| `testgen test` | Run existing tests | Executes tests â†’ Shows status | `--verbose` |
| `testgen report` | Generate documentation | Creates HTML/PDF report | `--pdf` |
| `testgen auto` | Do everything | Full pipeline (One-click) | N/A |

### Detailed Command Usage

#### Generate Tests
```bash
# Generate tests for a specific directory
testgen generate ./src

# Generate with live watch mode
testgen generate ./src --watch

# Specify output directory
testgen generate ./src --output ./tests
```

#### Run Tests
```bash
# Run all tests
testgen test

# Run with verbose output
testgen test --verbose

# Run specific test pattern
testgen test --pattern "test_user*"
```

#### Generate Reports
```bash
# Generate HTML report
testgen report

# Generate PDF report
testgen report --pdf

# Specify output path
testgen report --output ./reports/test_report.html
```

#### Auto Mode (God Mode)
```bash
# Do everything: generate â†’ test â†’ report
testgen auto ./src
```

---

## ğŸ“Š Terminal Dashboard

When tests execute, you'll see a beautiful matrix like this:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    TEST EXECUTION MATRIX                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Test Name                     â•‘ Status   â•‘ Duration â•‘ Details    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ test_user_login               â•‘ âœ” PASS   â•‘ 0.24s    â•‘            â•‘
â•‘ test_user_registration        â•‘ âœ” PASS   â•‘ 0.31s    â•‘            â•‘
â•‘ test_password_validation      â•‘ âœ˜ FAIL   â•‘ 0.12s    â•‘ AssertionEâ€¦â•‘
â•‘ test_database_connection      â•‘ âœ” PASS   â•‘ 5.01s    â•‘ [SLOW]     â•‘
â•‘ test_api_endpoint_users       â•‘ âœ” PASS   â•‘ 0.89s    â•‘            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•

Summary: 4 passed, 1 failed, 0 skipped | Total: 6.57s
```

### Color Coding
- âœ” **PASS**: Bold Green
- âœ˜ **FAIL**: Bold Red  
- âŠ˜ **SKIP**: Yellow
- **Duration**: <1s Green, 1-5s Yellow, >5s Red (Warning)

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Language** | Python 3.10+ | Modern syntax with pattern matching |
| **CLI Framework** | Typer | Type-hint based command validation |
| **Terminal UI** | Rich | Tables, spinners, syntax highlighting |
| **AI Layer** | LiteLLM | Model-agnostic (GPT/Claude/Ollama) |
| **Validation** | Pydantic | Strict JSON output from LLMs |
| **File Watching** | Watchdog | OS-level events (inotify/FSEvents) |
| **Testing Core** | Pytest | Test execution engine |
| **UI Testing** | Playwright | Headless browser automation |
| **Reporting** | Jinja2 | HTML/PDF template rendering |

---

## ğŸ“ Project Structure

```
testgen-ai/
â”œâ”€â”€ pyproject.toml           # Configuration & Dependencies
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ TASKS.md                 # Development roadmap (140 tasks)
â”œâ”€â”€ .env.example             # Environment variables template
â””â”€â”€ src/
    â””â”€â”€ testgen/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ main.py          # CLI Entry Point (Typer)
        â”œâ”€â”€ manager.py       # Workflow Orchestrator
        â”œâ”€â”€ config.py        # Settings & API Keys
        â”œâ”€â”€ core/            # Backend Logic
        â”‚   â”œâ”€â”€ scanner.py       # Code analyzer
        â”‚   â”œâ”€â”€ llm.py           # AI integration
        â”‚   â”œâ”€â”€ runner.py        # Test executor
        â”‚   â””â”€â”€ watcher.py       # Watch mode handler
        â””â”€â”€ ui/              # Frontend Visuals
            â”œâ”€â”€ printer.py       # Terminal matrix renderer
            â””â”€â”€ reporter.py      # HTML/PDF generator
```

---

## ğŸ“ Usage Examples

### Example 1: Generate Tests for a Python Module

```bash
# Your project structure
my_app/
â”œâ”€â”€ calculator.py
â””â”€â”€ utils.py

# Generate tests
testgen generate ./my_app

# Result: tests/ directory created
tests/
â”œâ”€â”€ test_calculator.py
â””â”€â”€ test_utils.py
```

### Example 2: Watch Mode for TDD

```bash
# Start watch mode
testgen generate ./src --watch --auto-run

# Now edit src/user.py
# â†’ TestGen AI detects change
# â†’ Generates tests/test_user.py
# â†’ Runs tests automatically
# â†’ Shows results in terminal
```

### Example 3: CI/CD Integration

```yaml
# .github/workflows/test.yml
name: Test
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Install TestGen AI
        run: pip install testgen-ai
      - name: Generate and Run Tests
        run: testgen auto ./src
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
```

---

## âš™ï¸ Configuration

Create a `.env` file in your project root:

```bash
# LLM Provider (choose one)
OPENAI_API_KEY=sk-your-key-here
ANTHROPIC_API_KEY=your-claude-key

# Model Selection
LLM_MODEL=gpt-4                    # or gpt-3.5-turbo, claude-3, ollama/codellama

# Test Generation Settings
TEST_FRAMEWORK=pytest              # or unittest
TEST_OUTPUT_DIR=./tests
MAX_CONTEXT_TOKENS=8000

# Watch Mode Settings
WATCH_DEBOUNCE_SECONDS=2
WATCH_AUTO_RUN=true
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes** following our coding standards
4. **Run tests**: `pytest`
5. **Commit your changes**: `git commit -m 'Add amazing feature'`
6. **Push to branch**: `git push origin feature/amazing-feature`
7. **Open a Pull Request**

See [TASKS.md](TASKS.md) for the development roadmap.

---

## ğŸ“ Development Roadmap

The project is organized into **10 modules** with **140 sequential tasks**. See [TASKS.md](TASKS.md) for details:

- âœ… Module 0: Project Setup (Tasks 1-9)
- ğŸŸ¡ Module 1: CLI Framework (Tasks 10-21)
- â¬œ Module 2: Code Scanner (Tasks 22-32)
- â¬œ Module 3: LLM Integration (Tasks 33-46)
- â¬œ Module 4: Test Runner (Tasks 47-58)
- â¬œ Module 5: Watch Mode (Tasks 59-68)
- â¬œ Module 6: Terminal UI (Tasks 69-79)
- â¬œ Module 7: Report Generation (Tasks 80-91)
- â¬œ Module 8: Workflow Orchestration (Tasks 92-103)
- â¬œ Module 9: Integration Testing (Tasks 104-119)
- â¬œ Module 10: Documentation & Deployment (Tasks 120-140)

---

## ğŸ› Troubleshooting

### Issue: "API Key not found"
**Solution**: Create a `.env` file with your API key:
```bash
echo "OPENAI_API_KEY=sk-your-key" > .env
```

### Issue: "No tests generated"
**Solution**: Ensure your code files have docstrings and are not empty. TestGen AI works best with well-documented code.

### Issue: "Command not found: testgen"
**Solution**: Install in editable mode or add to PATH:
```bash
pip install -e .
# OR
export PATH="$PATH:$HOME/.local/bin"
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Built with [Typer](https://typer.tiangolo.com/) for the CLI
- Powered by [Rich](https://rich.readthedocs.io/) for beautiful terminal output
- AI integration via [LiteLLM](https://github.com/BerriAI/litellm)
- Inspired by the need for better developer tooling in the AI era

---

## ğŸ“§ Contact & Support

- **Author**: Jay Patil
- **GitHub**: [@JayPatil165](https://github.com/JayPatil165)
- **Issues**: [GitHub Issues](https://github.com/JayPatil165/TestGen-AI/issues)
- **Discussions**: [GitHub Discussions](https://github.com/JayPatil165/TestGen-AI/discussions)

---

<p align="center">
  <strong>â­ Star this repo if you find it useful! â­</strong>
</p>

<p align="center">
  Made with â¤ï¸ by developers, for developers
</p>
